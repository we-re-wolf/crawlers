# crawlers
Crawlers are used to create a site map. It is a very useful tool which helps in red teaming to find directories as well as files and subdomains.

This program has two parts(for now), the grabber helps capturing all the backlinks which are present in a particular website and the crawlers help in finding all the subdomains and directories and files present in an web application.

You can use this tools on http as well as https, just change the request function to https in crawler.py and for grabber.py you just need to input your site as http:// or https://

Feel free to contribute and please install all the libraries after looking at the code.
